{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf11f34-e308-45ac-b984-f3065fac553b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/DeepSNUPI/lib/python3.9/site-packages/pandas/__init__.py:37\u001b[0m\n\u001b[1;32m     30\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_err\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     get_option,\n\u001b[1;32m     39\u001b[0m     set_option,\n\u001b[1;32m     40\u001b[0m     reset_option,\n\u001b[1;32m     41\u001b[0m     describe_option,\n\u001b[1;32m     42\u001b[0m     option_context,\n\u001b[1;32m     43\u001b[0m     options,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/DeepSNUPI/lib/python3.9/site-packages/pandas/_config/__init__.py:20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mpandas._config is considered explicitly upstream of everything else in pandas,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mshould have no intra-pandas dependencies.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mare initialized.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect_console_encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn_copy_on_write\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dates  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     _global_config,\n\u001b[1;32m     24\u001b[0m     describe_option,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     set_option,\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/DeepSNUPI/lib/python3.9/site-packages/pandas/_config/config.py:68\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     59\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m     60\u001b[0m     Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     cast,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     F,\n\u001b[1;32m     70\u001b[0m     T,\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/.conda/envs/DeepSNUPI/lib/python3.9/site-packages/pandas/_typing.py:198\u001b[0m\n\u001b[1;32m    192\u001b[0m Frequency \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseOffset\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    193\u001b[0m Axes \u001b[38;5;241m=\u001b[39m ListLike\n\u001b[1;32m    195\u001b[0m RandomState \u001b[38;5;241m=\u001b[39m Union[\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    197\u001b[0m     np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m--> 198\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mGenerator,\n\u001b[1;32m    199\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mBitGenerator,\n\u001b[1;32m    200\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState,\n\u001b[1;32m    201\u001b[0m ]\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# dtypes\u001b[39;00m\n\u001b[1;32m    204\u001b[0m NpDtype \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mdtype, type_t[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mobject\u001b[39m]]]\n",
      "File \u001b[0;32m~/.conda/envs/DeepSNUPI/lib/python3.9/site-packages/numpy/__init__.py:337\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__dir__\u001b[39m():\n\u001b[0;32m--> 337\u001b[0m     public_symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m    338\u001b[0m     public_symbols \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrixlib\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;66;03m# These were moved in 1.25 and may be deprecated eventually:\u001b[39;00m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModuleDeprecationWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisibleDeprecationWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplexWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTooHardError\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAxisError\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m     }\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(public_symbols)\n",
      "File \u001b[0;32m~/.conda/envs/DeepSNUPI/lib/python3.9/site-packages/numpy/random/__init__.py:180\u001b[0m\n\u001b[1;32m    126\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzipf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    177\u001b[0m ]\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# add these for module-freeze analysis (like PyInstaller)\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pickle\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _common\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _bounded_integers\n",
      "File \u001b[0;32m~/.conda/envs/DeepSNUPI/lib/python3.9/site-packages/numpy/random/_pickle.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmtrand\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomState\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_philox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Philox\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pcg64\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCG64, PCG64DXSM\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:1\u001b[0m, in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee9bbe83-98fd-4690-91ad-46a9898fc13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mamba install pyg=*=*cu* -c pyg\n",
    "!mamba update pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96712572-b4f1-4c18-93ec-38accd0fff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Model for DNA Origami\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = pyg_nn.GCNConv(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.relu(self.conv1(x, edge_index))\n",
    "        x = self.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15d7e00a-b512-46fa-a4a5-f9d72cab667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for DNA configurations\n",
    "class DNADataset(Dataset):\n",
    "    def __init__(self, data, edge_index):\n",
    "        self.data = data\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        edge_index = torch.tensor(self.edge_index, dtype=torch.long)\n",
    "        return Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "259134a0-187f-4b32-a8b2-404e66b61520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angles(x):\n",
    "    \"\"\"\n",
    "    Computes the angles between consecutive nucleotides in the configuration.\n",
    "    Args:\n",
    "        x: Tensor of shape (batch_size, num_nucleotides, dim), where dim is usually 3, i.e. (x, y, z)\n",
    "\n",
    "    Returns:\n",
    "        Angles: Tensor of angles between three consecutive nucleotides.\n",
    "    \"\"\"\n",
    "    # Vector between nucleotide i and i+1\n",
    "    v1 = x[:, :-2] - x[:, 1:-1]\n",
    "    # Vector between nucleotide i+1 and i+2\n",
    "    v2 = x[:, 1:-1] - x[:, 2:]\n",
    "\n",
    "    # Compute the angle between vectors v1 and v2 using dot product and norm\n",
    "    v1_norm = torch.norm(v1, dim=-1)\n",
    "    v2_norm = torch.norm(v2, dim=-1)\n",
    "\n",
    "    dot_prod = (v1 * v2).sum(dim=-1)\n",
    "    cos_theta = dot_prod / (v1_norm * v2_norm)\n",
    "    cos_theta = torch.clamp(cos_theta, -1.0, 1.0)  # Clamp to avoid invalid values in acos\n",
    "    # angles in radians\n",
    "    angles = torch.acos(cos_theta)\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b7139b-fd0d-4c81-b74f-a63500c7fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epotential_backbone(x, R0=1.5, k=30):\n",
    "    r_ij = torch.norm(x[:, :-1] - x[:, 1:], dim=-1) + 1e-9\n",
    "    valid_mask = r_ij < R0  # Ensure distances are within valid range for log\n",
    "    r_ij = torch.clamp(r_ij, max=R0 - 1e-6)  # Avoid log of zero or negative values\n",
    "    potential = (k / 2) * R0**2 * torch.log(1 - (r_ij**2) / R0**2)\n",
    "    potential = torch.where(valid_mask, potential, torch.zeros_like(potential))  # Zero out invalid values\n",
    "    return potential.sum()\n",
    "\n",
    "\n",
    "def epotential_stacking(x, epsilon_stack=1.0):\n",
    "    r_ij = torch.norm(x[:, :-1] - x[:, 1:], dim=-1) + 1e-9\n",
    "    theta = calc_angles(x)\n",
    "    f1 = torch.exp(-1 * r_ij**2)\n",
    "    f2 = torch.cos(theta)\n",
    "    return -1 * epsilon_stack * (f1 * f2).sum()\n",
    "\n",
    "def hydrogen_bonding(x, base_pairs, epsilon_hb=2.0):\n",
    "    hb_energy = 0\n",
    "    batch_size = x.size(0)\n",
    "    for i, j in base_pairs:\n",
    "        if i < x.size(1) and j < x.size(1):  # Ensure indices are within bounds\n",
    "            r_ij = torch.norm(x[:, i] - x[:, j], dim=-1) + 1e-9\n",
    "            r_ij = torch.clamp(r_ij, min=1e-3)  # Avoid extremely small distances\n",
    "            theta_ij = calc_angles(torch.stack([x[:, i], x[:, j]], dim=1).view(batch_size, -1, 3))\n",
    "            hb_energy += -1 * epsilon_hb * torch.exp(-1 * r_ij) * torch.cos(theta_ij)\n",
    "    return hb_energy\n",
    "\n",
    "def excluded_volume(x, A=5.0, lambda_val=1.0):\n",
    "    r_ij = torch.norm(x[:, :, None] - x[:, None, :], dim=-1) + 1e-9\n",
    "    r_ij = torch.clamp(r_ij, min=1e-3)  # Avoid extremely small distances\n",
    "    return A * torch.exp(-1 * r_ij / lambda_val).sum()\n",
    "\n",
    "def coaxial_stacking(x, epsilon_coaxial=1.5):\n",
    "    r_ij = torch.norm(x[:, :-1] - x[:, 1:], dim=-1) + 1e-9\n",
    "    theta_ij = calc_angles(x)\n",
    "    return -1 * epsilon_coaxial * torch.exp(-1 * r_ij) * torch.cos(theta_ij).sum()\n",
    "\n",
    "def dna_energy_func(x, base_pairs):\n",
    "    e_backbone = epotential_backbone(x)\n",
    "    e_stacking = epotential_stacking(x)\n",
    "    e_hb = hydrogen_bonding(x, base_pairs)\n",
    "    e_excluded = excluded_volume(x)\n",
    "    e_coaxial = coaxial_stacking(x)\n",
    "    e_total = e_backbone + e_stacking + e_hb + e_excluded + e_coaxial\n",
    "    return e_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f31a53-67a4-43c4-b0f5-8ada7cdb1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL Divergence Loss with Energy Function\n",
    "def kl_divergence_loss(model, data, base_pairs, energy_func):\n",
    "    x = model(data)\n",
    "    energy = energy_func(x, base_pairs)\n",
    "    kl_loss = energy.mean()\n",
    "    if torch.isnan(kl_loss):\n",
    "        print(\"NaN detected in KL loss! Debugging information:\")\n",
    "        print(f\"Energy: {energy}\")\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973a31a-a1d1-41e0-95ba-54f929e3a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def monitor_gradients(model):\n",
    "#     for name, param in model.named_parameters():\n",
    "#         # print(f\"Layer {name}; Gradient norm = {param.grad.norm()}\")\n",
    "#         if param.grad is not None:\n",
    "#             print(f\"Layer {name}; Gradient norm = {param.grad.norm()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005eee4-bbd6-423c-a481-86a76e493a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_weights(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         torch.nn.init.xavier_uniform_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             torch.nn.init.zeros_(m.bias) # init biases to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a14e04-cc20-4ade-b348-e4d1510d4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler, base_pairs, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in dataloader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = kl_divergence_loss(model, data, base_pairs, dna_energy_func)\n",
    "            if torch.isnan(loss):\n",
    "                print(\"Skipping batch due to NaN loss.\")\n",
    "                continue  # Skip this batch if loss is NaN\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)  # Reduce gradient clipping value\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step(total_loss / len(dataloader))  # Update the learning rate scheduler\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} -> Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fbb8ed-700a-419f-951b-099f287070c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling new DNA configurations from latent space\n",
    "def sample_dna_configs(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_generated = model(data)\n",
    "        return x_generated.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525daa43-0572-4cf6-8afa-e6a96d8b9e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Randomly generated data for demo\n",
    "input_dim = 9  # Input dimension to include position, a1, and a3 vectors\n",
    "hidden_dim = 128\n",
    "output_dim = 3  # Output dimension (x, y, z)\n",
    "learning_rate = 0.0001\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00067075-e866-4409-8b42-a35d405146a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./data/output.oxview\", 'r') as file:\n",
    "#     json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1785b12d-da07-4746-bcf6-5044306b4599",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m system \u001b[38;5;129;01min\u001b[39;00m \u001b[43mjson_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystems\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m strand \u001b[38;5;129;01min\u001b[39;00m system[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrands\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m monomer \u001b[38;5;129;01min\u001b[39;00m strand[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonomers\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_data' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "position_data = []\n",
    "base_pairs = []\n",
    "monomer_index_map = {}  # Map to keep track of monomer IDs and their indices in the data array\n",
    "idx = 0\n",
    "edge_index = []\n",
    "for system in json_data['systems']:\n",
    "    for strand in system['strands']:\n",
    "        for monomer in strand['monomers']:\n",
    "            p = monomer['p'] + monomer['a1'] + monomer['a3']  # Concatenate position (x, y, z) with internal vectors a1 and a3 to get input_dim = 9\n",
    "            position_data.append(p)\n",
    "            monomer_index_map[monomer['id']] = idx\n",
    "            idx += 1\n",
    "            # Check if monomer has a base pair\n",
    "            if 'bp' in monomer and monomer['bp'] in monomer_index_map:\n",
    "                base_pairs.append((monomer_index_map[monomer['id']], monomer_index_map[monomer['bp']]))\n",
    "            # Add edges for GNN (backbone connections)\n",
    "            if idx > 0:\n",
    "                edge_index.append([idx - 1, idx])\n",
    "                edge_index.append([idx, idx - 1])\n",
    "position_data = np.array(position_data)\n",
    "edge_index = np.array(edge_index).T  # Transpose to match PyG format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbffbfae-92dc-4e35-944e-7ce173af2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [torch.randn(1, input_dim) for _ in range(100)] # we will replace with actual dna coords/oxDNA datasets\n",
    "# data = np.random.randn(1000, input_dim)\n",
    "dataset = DNAOrigamiDataset(position_data)\n",
    "# data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e7eed5b5-449d-4833-b571-5d05e5b44eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 -> Loss: -247.1958\n",
      "Epoch 2/50 -> Loss: -249.9794\n",
      "Epoch 3/50 -> Loss: -249.9796\n",
      "Epoch 4/50 -> Loss: -249.9796\n",
      "Epoch 5/50 -> Loss: -249.9797\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Sample base pairs (replace with realistic pairs for DNA)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# base_pairs = [(0, 7), (1, 6), (2, 5), (3, 4)]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrealnvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[100], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, base_pairs, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m monitor_gradients(model)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# if torch.isnan(loss):\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     continue # Skip this batch if loss is NaN\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # Model, optimizer, and training\n",
    "realnvp = RealNVP(input_dim, num_layers).to(device)\n",
    "realnvp.apply(initialize_weights)\n",
    "optimizer = optim.Adam(realnvp.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Sample base pairs (replace with realistic pairs for DNA)\n",
    "# base_pairs = [(0, 7), (1, 6), (2, 5), (3, 4)]\n",
    "\n",
    "# Train the model\n",
    "train(realnvp, dataloader, optimizer, base_pairs, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca44a302-e6dc-47ac-b72d-2b8efb87bb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.71860695e+00 -9.27713990e-01 -7.84954250e-01 -1.26351155e-02\n",
      "  -1.15915164e-02 -8.71867780e-03]\n",
      " [-5.28648905e-02  9.03109014e-02 -1.98490396e-01 -2.02346407e-02\n",
      "  -4.08926718e-02 -1.74785182e-02]\n",
      " [ 2.07511753e-01 -7.60903358e-01 -7.22222805e-01 -4.96835215e-03\n",
      "  -8.53362028e-03 -2.73933727e-02]\n",
      " [ 6.45293742e-02 -6.42429411e-01 -1.44040453e+00  7.56772701e-03\n",
      "   2.90152850e-03 -1.62262004e-02]\n",
      " [-1.92330942e-01  1.80773631e-01 -3.92905444e-01 -2.24663224e-03\n",
      "  -3.06282844e-02 -1.42831663e-02]\n",
      " [ 1.18639970e+00  1.75999510e+00  4.19231027e-01 -6.43657744e-02\n",
      "  -4.34665978e-02  1.04686674e-02]\n",
      " [-3.27538401e-01  1.34096992e+00 -1.08950031e+00  2.16821488e-03\n",
      "  -1.66193694e-02  1.68389790e-02]\n",
      " [ 9.00311470e-02  1.66173005e+00 -2.48448133e-01 -3.01189553e-02\n",
      "  -3.59693840e-02  1.19226221e-02]\n",
      " [-2.42928982e-01 -8.11607480e-01 -2.25642040e-01  6.29604375e-03\n",
      "  -1.54456720e-02 -1.92963537e-02]\n",
      " [-1.17423284e+00 -1.62350559e+00  1.24952888e+00  9.48551856e-03\n",
      "  -1.27476389e-02 -6.29601208e-03]]\n"
     ]
    }
   ],
   "source": [
    "new_dna_configs = sample_dna_configs(realnvp, num_samples=10, input_dim=input_dim)\n",
    "print(new_dna_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b91772-ccb0-4be9-a7b9-7c2c0860906a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepSnupi",
   "language": "python",
   "name": "deepsnupi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
